<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/Blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/Blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/Blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/Blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/Blog/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yexiaorain.github.io","root":"/Blog/","images":"/Blog/images","scheme":"Muse","darkmode":false,"version":"8.12.3","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"},"path":"/Blog/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/Blog/js/config.js"></script>

    <meta name="description" content="表格整理 图片主要来源于官方的讲义PDF以及Wikipedia 监督学习线性回归将输入数据，如图中的红点，求得一条直线表示数据中的线性关系，并且这条直线在概率期望上达到最佳(后面算法省略这句)。  梯度下降找函数极值小值点，图中相同颜色线为等高线，越靠近中心高度越低，运用高数的梯度运算和梯度下降能够得到如图中蓝色x标记的逐步逼近的极值点。  Normal Equation同样是解决线性回归问题，和">
<meta property="og:type" content="article">
<meta property="og:title" content="Stanford Machine Learning 科普">
<meta property="og:url" content="https://yexiaorain.github.io/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/index.html">
<meta property="og:site_name" content="YeXiaoRain Blog">
<meta property="og:description" content="表格整理 图片主要来源于官方的讲义PDF以及Wikipedia 监督学习线性回归将输入数据，如图中的红点，求得一条直线表示数据中的线性关系，并且这条直线在概率期望上达到最佳(后面算法省略这句)。  梯度下降找函数极值小值点，图中相同颜色线为等高线，越靠近中心高度越低，运用高数的梯度运算和梯度下降能够得到如图中蓝色x标记的逐步逼近的极值点。  Normal Equation同样是解决线性回归问题，和">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/xxhg.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/tdxj.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/NormalEquations.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/logistics.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/gsqx.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/GLM.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/softmax.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/GDA.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/bayes.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/Laplace.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/geometricmargins.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/KKT.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/Kernel.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/SVM.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/L1regularization.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/SMO.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/MSE.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/Error.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/kmeans.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/GMM.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/EM.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/Factor.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/PCA.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/ICA.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/MDP.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/MDPlsh.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/simulator.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/LQR.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/kalman.jpg">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/DDP.png">
<meta property="og:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/policysearch.png">
<meta property="article:published_time" content="2018-04-18T15:33:33.000Z">
<meta property="article:modified_time" content="2022-10-26T10:35:28.034Z">
<meta property="article:author" content="Xiao Ye">
<meta property="article:tag" content="Machine learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yexiaorain.github.io/Blog/Blog/img/ML/xxhg.png">


<link rel="canonical" href="https://yexiaorain.github.io/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-TW","comments":true,"permalink":"https://yexiaorain.github.io/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/","path":"2018-04-18-Stanford_Machine_Learning_with_graph/","title":"Stanford Machine Learning 科普"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Stanford Machine Learning 科普 | YeXiaoRain Blog</title>
  





  <noscript>
    <link rel="stylesheet" href="/Blog/css/noscript.css">
  </noscript>
<link rel="alternate" href="/Blog/atom.xml" title="YeXiaoRain Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/Blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">YeXiaoRain Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/Blog/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li><li class="menu-item menu-item-archives"><a href="/Blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔<span class="badge">206</span></a></li><li class="menu-item menu-item-rss"><a href="/Blog/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>rss</a></li><li class="menu-item menu-item-categories"><a href="/Blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類<span class="badge">15</span></a></li><li class="menu-item menu-item-tags"><a href="/Blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤<span class="badge">196</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜尋..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-text">监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-text">梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Normal-Equation"><span class="nav-text">Normal Equation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Logistics-%E5%9B%9E%E5%BD%92"><span class="nav-text">Logistics 回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E5%88%87%E7%BA%BF%E6%B3%95"><span class="nav-text">高斯切线法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8BGLM"><span class="nav-text">广义线性模型GLM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#softmax-%E5%9B%9E%E5%BD%92"><span class="nav-text">softmax 回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90GDA"><span class="nav-text">高斯判别分析GDA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="nav-text">朴素贝叶斯</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91"><span class="nav-text">拉普拉斯平滑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E4%BC%98%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-text">最优线性分类器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E3%80%81KKT"><span class="nav-text">拉格朗日对偶、KKT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="nav-text">核函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM"><span class="nav-text">支持向量机SVM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L1-Regularization"><span class="nav-text">L1 Regularization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SMO"><span class="nav-text">SMO</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AEMSE"><span class="nav-text">均方误差MSE</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%94%99%E8%AF%AF%E5%88%86%E6%9E%90"><span class="nav-text">错误分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VC%E7%BB%B4%E3%80%81hoeffding%E4%B8%8D%E5%AE%9A%E5%BC%8F"><span class="nav-text">VC维、hoeffding不定式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AA%8C%E8%AF%81%E6%96%B9%E5%BC%8F%E3%80%81%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="nav-text">验证方式、模型选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E5%99%A8"><span class="nav-text">感知器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-text">无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#k-means"><span class="nav-text">k-means</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8BGMM"><span class="nav-text">高斯混合模型GMM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EM%E7%AE%97%E6%B3%95"><span class="nav-text">EM算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90"><span class="nav-text">因子分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA"><span class="nav-text">主成分分析PCA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8B%AC%E7%AB%8B%E6%88%90%E5%88%86%E5%88%86%E6%9E%90ICA"><span class="nav-text">独立成分分析ICA</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B"><span class="nav-text">马尔科夫模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-MDP"><span class="nav-text">马尔科夫决策过程 MDP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A6%BB%E6%95%A3%E5%8C%96%E8%BF%9E%E7%BB%AD%E7%8A%B6%E6%80%81%E7%9A%84MDP"><span class="nav-text">离散化连续状态的MDP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MDP%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%A8%A1%E6%8B%9F%E5%99%A8"><span class="nav-text">MDP中的模型模拟器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E4%BA%8C%E6%AC%A1%E5%9E%8B%E8%B0%83%E8%8A%82%E6%8E%A7%E5%88%B6LQR"><span class="nav-text">线性二次型调节控制LQR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kalman%E6%BB%A4%E6%B3%A2"><span class="nav-text">kalman滤波</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LQG"><span class="nav-text">LQG</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BE%AE%E5%88%86%E5%8A%A8%E8%A7%84DDP"><span class="nav-text">微分动规DDP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pegasus%E7%AD%96%E7%95%A5%E6%90%9C%E7%B4%A2"><span class="nav-text">pegasus策略搜索</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xiao Ye"
      src="https://avatars.githubusercontent.com/u/7298239?v=4">
  <p class="site-author-name" itemprop="name">Xiao Ye</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/Blog/archives/">
          <span class="site-state-item-count">206</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/Blog/categories/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/Blog/tags/">
        <span class="site-state-item-count">196</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/yexiaorain" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yexiaorain" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yexiaorain@gmail.com" title="E-Mail → mailto:yexiaorain@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://atcoder.jp/users/cromarmot" title="https:&#x2F;&#x2F;atcoder.jp&#x2F;users&#x2F;cromarmot" rel="noopener" target="_blank">AtCoder</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://codeforces.com/profile/YeXiaoRain" title="https:&#x2F;&#x2F;codeforces.com&#x2F;profile&#x2F;YeXiaoRain" rel="noopener" target="_blank">Codeforces</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://yexiaorain.github.io/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/7298239?v=4">
      <meta itemprop="name" content="Xiao Ye">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YeXiaoRain Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Stanford Machine Learning 科普 | YeXiaoRain Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Stanford Machine Learning 科普
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2018-04-18 23:33:33" itemprop="dateCreated datePublished" datetime="2018-04-18T23:33:33+08:00">2018-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-10-26 18:35:28" itemprop="dateModified" datetime="2022-10-26T18:35:28+08:00">2022-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分類於</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Blog/categories/Machine-learning/" itemprop="url" rel="index"><span itemprop="name">Machine learning</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018-04-18-Stanford_Machine_Learning_with_graph/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="文章字數">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">文章字數：</span>
      <span>2k</span>
    </span>
    <span class="post-meta-item" title="所需閱讀時間">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">所需閱讀時間 &asymp;</span>
      <span>5 分鐘</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p><a href="https://yexiaorain.github.io/Blog/2018-04-17-Stanford_Machine_Learning/">表格整理</a></p>
<p><strong>图片主要来源于官方的讲义PDF以及Wikipedia</strong></p>
<h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>将输入数据，如图中的红点，求得一条直线表示数据中的线性关系，并且这条直线在概率期望上达到最佳(后面算法省略这句)。</p>
<p><img data-src="/Blog/Blog/img/ML/xxhg.png" alt="线性回归"></p>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>找函数极值小值点，图中相同颜色线为等高线，越靠近中心高度越低，运用高数的梯度运算和梯度下降能够得到如图中蓝色x标记的逐步逼近的极值点。</p>
<p><img data-src="/Blog/Blog/img/ML/tdxj.png" alt="梯度下降"></p>
<h2 id="Normal-Equation"><a href="#Normal-Equation" class="headerlink" title="Normal Equation"></a>Normal Equation</h2><p>同样是解决线性回归问题，和梯度下降不同的是，运用矩阵运算，直接得到参数的表达式</p>
<p><img data-src="/Blog/Blog/img/ML/NormalEquations.png" alt="Normal Equations"></p>
<h2 id="Logistics-回归"><a href="#Logistics-回归" class="headerlink" title="Logistics 回归"></a>Logistics 回归</h2><p>分类算法，对一侧数据0，另一侧数据1的训练数据建立分类器，图中的点是 训练输入，线是得到的logistics函数</p>
<p><img data-src="/Blog/Blog/img/ML/logistics.png" alt="logistics"></p>
<h2 id="高斯切线法"><a href="#高斯切线法" class="headerlink" title="高斯切线法"></a>高斯切线法</h2><p>高数知识，二次收敛，加速点的收敛，如图 通过计算切线与坐标轴的交点作为下一次的迭代起始值。</p>
<p><img data-src="/Blog/Blog/img/ML/gsqx.png" alt="gao si qie xian"></p>
<h2 id="广义线性模型GLM"><a href="#广义线性模型GLM" class="headerlink" title="广义线性模型GLM"></a>广义线性模型GLM</h2><p>按照所提出的假设模型，能够<code>直接</code>得到所需要的 拟合函数，可以用来证明上面 的线性回归中最小二乘法是最优，以及Logistics 回归中的函数选取。</p>
<p><img data-src="/Blog/Blog/img/ML/GLM.png" alt="GLM"></p>
<h2 id="softmax-回归"><a href="#softmax-回归" class="headerlink" title="softmax 回归"></a>softmax 回归</h2><p>分类到对互斥的k个类别,公式推导采用带入GLM</p>
<p><img data-src="/Blog/Blog/img/ML/softmax.png" alt="softmax"></p>
<h2 id="高斯判别分析GDA"><a href="#高斯判别分析GDA" class="headerlink" title="高斯判别分析GDA"></a>高斯判别分析GDA</h2><p>对0分布满足高斯分布，1分布也满足高斯分布的分布进行线性分类。</p>
<p><img data-src="/Blog/Blog/img/ML/GDA.png" alt="GDA"></p>
<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p>整体与特征来判断整体的分类，如垃圾邮件根据出现的词汇进行分类，很暴力直接计算概率</p>
<p><img data-src="/Blog/Blog/img/ML/bayes.png" alt="bayes"></p>
<h2 id="拉普拉斯平滑"><a href="#拉普拉斯平滑" class="headerlink" title="拉普拉斯平滑"></a>拉普拉斯平滑</h2><p>解决朴素贝叶斯中可能出现的0除以0的情况，分子+1，分母+可分的种类数k</p>
<p><img data-src="/Blog/Blog/img/ML/Laplace.png" alt="laplace"></p>
<h2 id="最优线性分类器"><a href="#最优线性分类器" class="headerlink" title="最优线性分类器"></a>最优线性分类器</h2><p>如图能够找到将 数据分开，并且离分割线最近的点的距离值最大的分类器。</p>
<p><img data-src="/Blog/Blog/img/ML/geometricmargins.png" alt="jihejuli"></p>
<h2 id="拉格朗日对偶、KKT"><a href="#拉格朗日对偶、KKT" class="headerlink" title="拉格朗日对偶、KKT"></a>拉格朗日对偶、KKT</h2><p>用于具体解决 最优线性分类器的支撑方法</p>
<p><img data-src="/Blog/Blog/img/ML/KKT.png" alt="KKT"></p>
<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>将变量非线性变化映射到高维空间，减小计算量，表示量，配合其它算法使用能获得高维空间性质。</p>
<p><img data-src="/Blog/Blog/img/ML/Kernel.png" alt="Kernel"></p>
<h2 id="支持向量机SVM"><a href="#支持向量机SVM" class="headerlink" title="支持向量机SVM"></a>支持向量机SVM</h2><p>将低维不可线性分割的 通过核函数映射到高维度，再在高维中进行最优线性分割</p>
<p><img data-src="/Blog/Blog/img/ML/SVM.png" alt="SVM"></p>
<h2 id="L1-Regularization"><a href="#L1-Regularization" class="headerlink" title="L1 Regularization"></a>L1 Regularization</h2><p>在有部分异常点时的分割,通过添加惩罚项解决如下图异常点导致变化过大的问题。</p>
<p><img data-src="/Blog/Blog/img/ML/L1regularization.png" alt="L1regularization"></p>
<h2 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h2><p>对于多个参数 每次选一个参数进行取极值点，SMO能在带等式与不等式的约束限定情况下，每次两个参数逐步逼近。</p>
<p><img data-src="/Blog/Blog/img/ML/SMO.png" alt="SMO"></p>
<h2 id="均方误差MSE"><a href="#均方误差MSE" class="headerlink" title="均方误差MSE"></a>均方误差MSE</h2><p>能够用于分析 过拟合 还是 欠拟合</p>
<p><img data-src="/Blog/Blog/img/ML/MSE.png" alt="mse"></p>
<h2 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h2><p>按步骤替代&#x2F;隔离分析，逐个增加或逐个减少。按训练误差 方差，实验 误差方差分析。</p>
<p><img data-src="/Blog/Blog/img/ML/Error.png" alt="error"></p>
<h2 id="VC维、hoeffding不定式"><a href="#VC维、hoeffding不定式" class="headerlink" title="VC维、hoeffding不定式"></a>VC维、hoeffding不定式</h2><p>用于证明概率下训练集和误差的上下界存在性。</p>
<h2 id="验证方式、模型选择"><a href="#验证方式、模型选择" class="headerlink" title="验证方式、模型选择"></a>验证方式、模型选择</h2><p>将部分的训练数据不用于训练而用于检验模型</p>
<h2 id="感知器"><a href="#感知器" class="headerlink" title="感知器"></a>感知器</h2><p>感知器：转换后的值小于0输出-1，大于等于0输出</p>
<h1 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h1><h2 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h2><p>对无标记的点进行分类(寻找分类的中心)</p>
<p><img data-src="/Blog/Blog/img/ML/kmeans.png" alt="kmeans"></p>
<h2 id="高斯混合模型GMM"><a href="#高斯混合模型GMM" class="headerlink" title="高斯混合模型GMM"></a>高斯混合模型GMM</h2><p>可以看作类似前面的高斯判别模型GDA，但是现在的输入数据是无标记的</p>
<p><img data-src="/Blog/Blog/img/ML/GMM.png" alt="GMM"></p>
<h2 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h2><p>用于GMM等无标记的混合模型的分离，先假设隐含变量Z以及它的分布Q，和k-means的思想类似，E-step优化Q，M-step优化参数，重复直到收敛 [使用Jensen不等式],分离效果见上图</p>
<p><img data-src="/Blog/Blog/img/ML/EM.png" alt="EM"></p>
<h2 id="因子分析"><a href="#因子分析" class="headerlink" title="因子分析"></a>因子分析</h2><p>对训练集量少，维数大，分类的类别少的分布进行分类，思想是建立隐含低维度变量z，通过矩阵转化投影到高维，再加上高斯扰动误差</p>
<p><img data-src="/Blog/Blog/img/ML/Factor.png" alt="Factor"></p>
<h2 id="主成分分析PCA"><a href="#主成分分析PCA" class="headerlink" title="主成分分析PCA"></a>主成分分析PCA</h2><p>对于高维空间的数据，找到其前k个相互正交的关键维度的向量，可用线性代数奇异值分解SVD进行快速计算。可以用于降维度，作为其它算法的预处理步骤，或找到关系的主要方面。</p>
<p><img data-src="/Blog/Blog/img/ML/PCA.png" alt="PCA"></p>
<h2 id="独立成分分析ICA"><a href="#独立成分分析ICA" class="headerlink" title="独立成分分析ICA"></a>独立成分分析ICA</h2><p>对于多维度，相互独立的非高斯分布成分，找到每个成分的轴，并将所有轴转换为正交轴。可用于特征提取，特征分离，如音频分离，计算人脸识别面部特征向量，对脑电波数据分离预处理去除眨眼和心跳信号。</p>
<p><img data-src="/Blog/Blog/img/ML/ICA.png" alt="ICA"></p>
<h1 id="马尔科夫模型"><a href="#马尔科夫模型" class="headerlink" title="马尔科夫模型"></a>马尔科夫模型</h1><h2 id="马尔科夫决策过程-MDP"><a href="#马尔科夫决策过程-MDP" class="headerlink" title="马尔科夫决策过程 MDP"></a>马尔科夫决策过程 MDP</h2><p>能够学习带有状态，和基于状态动作的一类事情，学出一个策略集，如自动驾驶，需要设置奖励函数，概率函数等参数函数。策略迭代和值迭代</p>
<p><img data-src="/Blog/Blog/img/ML/MDP.png" alt="MDP"></p>
<h2 id="离散化连续状态的MDP"><a href="#离散化连续状态的MDP" class="headerlink" title="离散化连续状态的MDP"></a>离散化连续状态的MDP</h2><p>也就是字面意思离散化，在2维下工作一般不错，高维度后无论是维数灾难还是离散化难度，以及模型最终产物都难以普遍满意</p>
<p><img data-src="/Blog/Blog/img/ML/MDPlsh.png" alt="MDPlsh"></p>
<h2 id="MDP中的模型模拟器"><a href="#MDP中的模型模拟器" class="headerlink" title="MDP中的模型模拟器"></a>MDP中的模型模拟器</h2><p>用于概率状态未知时，用实验+拟合得到模型，从而代替概率函数的位置</p>
<p><img data-src="/Blog/Blog/img/ML/simulator.png" alt="simulator"></p>
<h2 id="线性二次型调节控制LQR"><a href="#线性二次型调节控制LQR" class="headerlink" title="线性二次型调节控制LQR"></a>线性二次型调节控制LQR</h2><p>解决状态依赖于前一个状态前一个动作以及时间的策略选择，在有限时间内用动规(倒着递推)，多次实验线性拟合基于时间的。对于非线性函数仅能取较近的输入值，用近似的切线做近似的线性处理。通过加强奖励函数，初始值(时间T)矩阵，等限定。得出结论，动作与状态的线性相关，且计算过程中可以省去无关迭代</p>
<p><img data-src="/Blog/Blog/img/ML/LQR.png" alt="LQR"></p>
<h2 id="kalman滤波"><a href="#kalman滤波" class="headerlink" title="kalman滤波"></a>kalman滤波</h2><p>将<code>观测值</code>转化为概率上的<code>真实值</code></p>
<p><img data-src="/Blog/Blog/img/ML/kalman.jpg" alt="kalman"></p>
<h2 id="LQG"><a href="#LQG" class="headerlink" title="LQG"></a>LQG</h2><p>LQG&#x3D;LQR+kalman滤波</p>
<h2 id="微分动规DDP"><a href="#微分动规DDP" class="headerlink" title="微分动规DDP"></a>微分动规DDP</h2><p>根据当前决策选定轨迹，做LQR，更新决策，重复。从函数上理解是函数逐步靠近，即使是一个不那么好的模拟器</p>
<p><img data-src="/Blog/Blog/img/ML/DDP.png" alt="DDP"></p>
<h2 id="pegasus策略搜索"><a href="#pegasus策略搜索" class="headerlink" title="pegasus策略搜索"></a>pegasus策略搜索</h2><p>处理非线性模型函数的情况。选取随机序列并重复使用于模型训练，在模型选择时选取非线性的模型(如logistics 函数)，用极大似然去找该模型下的最优策略。</p>
<p><img data-src="/Blog/Blog/img/ML/policysearch.png" alt="policy"></p>

    </div>

    
    
    
      


    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>作者： </strong>Xiao Ye
  </li>
  <li class="post-copyright-link">
      <strong>文章連結：</strong>
      <a href="https://yexiaorain.github.io/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/" title="Stanford Machine Learning 科普">https://yexiaorain.github.io/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版權聲明： </strong>本網誌所有文章除特別聲明外，均採用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 許可協議。轉載請註明出處！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/Blog/tags/Machine-learning/" rel="tag"><i class="fa fa-tag"></i> Machine learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/Blog/2018-04-17-Stanford_Machine_Learning/" rel="prev" title="Stanford Machine Learning 学习笔记、个人整理">
                  <i class="fa fa-chevron-left"></i> Stanford Machine Learning 学习笔记、个人整理
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/Blog/2018-05-11-lisanhua/" rel="next" title="离散化">
                  离散化 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiao Ye</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="總字數">934k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="所需總閱讀時間">38:55</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/Blog/js/comments.js"></script><script src="/Blog/js/utils.js"></script><script src="/Blog/js/schemes/muse.js"></script><script src="/Blog/js/next-boot.js"></script><script src="/Blog/js/bookmark.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/Blog/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/Blog/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.2.0/quicklink.umd.js" integrity="sha256-4kQf9z5ntdQrzsBC3YSHnEz02Z9C1UeW/E9OgnvlzSY=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://yexiaorain.github.io/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/"}</script>
  <script src="/Blog/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"yexiaorain","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/Blog/js/third-party/comments/disqus.js"></script>

</body>
</html>
