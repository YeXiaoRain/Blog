<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/Blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/Blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/Blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/Blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/Blog/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yexiaorain.github.io","root":"/Blog/","images":"/Blog/images","scheme":"Muse","darkmode":false,"version":"8.12.3","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"},"path":"/Blog/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/Blog/js/config.js"></script>

    <meta name="description" content="课程相关链接网易Stanford机器学习 官方网站 Github整理 部分课件 练习 笔记和练习 说明 该课程能学到什么？  基于统计模型，概率公式的不同学习方法，不涉及神经网络。  本文档不按照课的分化记录，而按照内容的分化记录。  省去具体实现，毕竟已经有足够的他人整理的资料，以及我也在pad上手写过了，没有这个重复工作的必要了。不过我会尽量把知识点依赖写清，如果心情不错的话，再提供一个相关的">
<meta property="og:type" content="article">
<meta property="og:title" content="Stanford Machine Learning 学习笔记、个人整理">
<meta property="og:url" content="https://yexiaorain.github.io/Blog/2018-04-17-Stanford_Machine_Learning/index.html">
<meta property="og:site_name" content="YeXiaoRain Blog">
<meta property="og:description" content="课程相关链接网易Stanford机器学习 官方网站 Github整理 部分课件 练习 笔记和练习 说明 该课程能学到什么？  基于统计模型，概率公式的不同学习方法，不涉及神经网络。  本文档不按照课的分化记录，而按照内容的分化记录。  省去具体实现，毕竟已经有足够的他人整理的资料，以及我也在pad上手写过了，没有这个重复工作的必要了。不过我会尽量把知识点依赖写清，如果心情不错的话，再提供一个相关的">
<meta property="og:locale" content="zh_TW">
<meta property="article:published_time" content="2018-04-17T14:33:44.000Z">
<meta property="article:modified_time" content="2023-02-05T10:19:18.630Z">
<meta property="article:author" content="Xiao Ye">
<meta property="article:tag" content="Machine learning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://yexiaorain.github.io/Blog/2018-04-17-Stanford_Machine_Learning/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-TW","comments":true,"permalink":"https://yexiaorain.github.io/Blog/2018-04-17-Stanford_Machine_Learning/","path":"2018-04-17-Stanford_Machine_Learning/","title":"Stanford Machine Learning 学习笔记、个人整理"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Stanford Machine Learning 学习笔记、个人整理 | YeXiaoRain Blog</title>
  





  <noscript>
    <link rel="stylesheet" href="/Blog/css/noscript.css">
  </noscript>
<link rel="alternate" href="/Blog/atom.xml" title="YeXiaoRain Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/Blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">YeXiaoRain Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/Blog/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li><li class="menu-item menu-item-archives"><a href="/Blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔<span class="badge">245</span></a></li><li class="menu-item menu-item-yearmonth"><a href="/Blog/yearmonth/" rel="section"><i class="fa fa-calendar-days fa-fw"></i>年月</a></li><li class="menu-item menu-item-categories"><a href="/Blog/categories/" rel="section"><i class="fa fa-shapes fa-fw"></i>分類<span class="badge">17</span></a></li><li class="menu-item menu-item-tags"><a href="/Blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤<span class="badge">237</span></a></li><li class="menu-item menu-item-rss"><a href="/Blog/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>rss</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜尋..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%BE%E7%A8%8B%E7%9B%B8%E5%85%B3%E9%93%BE%E6%8E%A5"><span class="nav-text">课程相关链接</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%B4%E6%98%8E"><span class="nav-text">说明</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BE%9D%E8%B5%96%E7%9F%A5%E8%AF%86"><span class="nav-text">依赖知识</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%85%E5%AE%B9"><span class="nav-text">内容</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-text">监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-text">方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%85%E5%8A%A9%E6%96%B9%E6%B3%95-x2F-%E5%AE%9A%E4%B9%89"><span class="nav-text">辅助方法&#x2F;定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%81%E6%98%8E"><span class="nav-text">证明</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-text">无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95-1"><span class="nav-text">方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%85%E5%8A%A9%E6%96%B9%E6%B3%95-x2F-%E5%AE%9A%E4%B9%89-1"><span class="nav-text">辅助方法&#x2F;定义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0RL-x2F-%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8BMDP"><span class="nav-text">强化学习RL&#x2F;马尔科夫模型MDP</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A"><span class="nav-text">解释</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-%E5%8F%98%E5%BD%A2-x2F-%E9%97%AE%E9%A2%98"><span class="nav-text">马尔科夫决策过程 变形&#x2F;问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Debug-19"><span class="nav-text">Debug 19</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E5%8F%A5%E8%AF%9D%E8%83%BD%E5%9B%9E%E7%AD%94%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9-TODO"><span class="nav-text">一句话能回答的知识点 TODO</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B6%E5%AE%83%E7%9F%A5%E8%AF%86%E7%82%B9-%E7%BB%86%E8%8A%82-TODO"><span class="nav-text">其它知识点 细节 TODO</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B6%E5%AE%83TODO"><span class="nav-text">其它TODO</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xiao Ye"
      src="https://avatars.githubusercontent.com/u/7298239?v=4">
  <p class="site-author-name" itemprop="name">Xiao Ye</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/Blog/archives/">
          <span class="site-state-item-count">245</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/Blog/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/Blog/tags/">
        <span class="site-state-item-count">237</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/yexiaorain" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yexiaorain" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yexiaorain@gmail.com" title="E-Mail → mailto:yexiaorain@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://atcoder.jp/users/cromarmot" title="https:&#x2F;&#x2F;atcoder.jp&#x2F;users&#x2F;cromarmot" rel="noopener" target="_blank">AtCoder</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://codeforces.com/profile/YeXiaoRain" title="https:&#x2F;&#x2F;codeforces.com&#x2F;profile&#x2F;YeXiaoRain" rel="noopener" target="_blank">Codeforces</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://yexiaorain.github.io/Blog/2018-04-17-Stanford_Machine_Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/7298239?v=4">
      <meta itemprop="name" content="Xiao Ye">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YeXiaoRain Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Stanford Machine Learning 学习笔记、个人整理 | YeXiaoRain Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Stanford Machine Learning 学习笔记、个人整理
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2018-04-17 22:33:44" itemprop="dateCreated datePublished" datetime="2018-04-17T22:33:44+08:00">2018-04-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2023-02-05 18:19:18" itemprop="dateModified" datetime="2023-02-05T18:19:18+08:00">2023-02-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分類於</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Blog/categories/Machine-learning/" itemprop="url" rel="index"><span itemprop="name">Machine learning</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/Blog/2018-04-17-Stanford_Machine_Learning/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018-04-17-Stanford_Machine_Learning/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="文章字數">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">文章字數：</span>
      <span>3.4k</span>
    </span>
    <span class="post-meta-item" title="所需閱讀時間">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">所需閱讀時間 &asymp;</span>
      <span>11 分鐘</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="课程相关链接"><a href="#课程相关链接" class="headerlink" title="课程相关链接"></a>课程相关链接</h1><p><a target="_blank" rel="noopener" href="https://open.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html">网易Stanford机器学习</a></p>
<p><a target="_blank" rel="noopener" href="http://cs229.stanford.edu/">官方网站</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Kivy-CN/Stanford-CS-229-CN">Github整理</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/econti/cs229">部分课件</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/zyxue/stanford-cs229">练习</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/HuangCongQing/MachineLearning_Ng">笔记和练习</a></p>
<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><blockquote>
<p>该课程能学到什么？</p>
</blockquote>
<p>基于统计模型，概率公式的不同学习方法，不涉及神经网络。</p>
<blockquote>
<p>本文档不按照课的分化记录，而按照内容的分化记录。</p>
</blockquote>
<p>省去具体实现，毕竟已经有足够的他人整理的资料，以及我也在pad上手写过了，没有这个重复工作的必要了。不过我会尽量把知识点依赖写清，如果心情不错的话，再提供一个相关的优秀的讲解链接。这里还是以框架和思想为主。其中部分公式省略了取值限制，具体原公式请参照讲义</p>
<h1 id="依赖知识"><a href="#依赖知识" class="headerlink" title="依赖知识"></a>依赖知识</h1><ul>
<li><p>高等数学</p>
<ul>
<li>积分</li>
<li>微分</li>
<li>偏导数，梯度</li>
<li>拉格朗日乘子法、KKT条件(拉格朗日对偶)</li>
<li>牛顿切线</li>
</ul>
</li>
<li><p>线性代数</p>
<ul>
<li>矩阵 乘法 转置 逆 秩 迹</li>
<li>SVD</li>
</ul>
</li>
<li><p>概率统计</p>
<ul>
<li>贝叶斯</li>
<li>高斯分布 多纬高斯分布</li>
<li>0-1分布 泊松分布 等等常见分布</li>
<li>极大似然估计</li>
</ul>
</li>
<li><p>算法</p>
<ul>
<li>动态规划</li>
</ul>
</li>
</ul>
<h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><ul>
<li>提供样例(输入，输出(类别))数据进行训练，从而学习出一个分类器&#x2F;学成一个带有功能的程序。</li>
</ul>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><table>
<thead>
<tr>
<th>名称</th>
<th>功能</th>
<th>对应的期望</th>
<th>实现</th>
<th>理解</th>
<th>知识依赖</th>
<th>课程集数</th>
</tr>
</thead>
<tbody><tr>
<td>线性回归</td>
<td>拟合出一条自变量与因变量的关系直线</td>
<td>平方和最小</td>
<td>梯度下降</td>
<td>局部极值</td>
<td>高数梯度</td>
<td>2</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>Normal equations</td>
<td>极值点梯度&#x3D;0</td>
<td>矩阵运算 对矩阵求梯度</td>
<td>2</td>
</tr>
<tr>
<td>线性回归(数据量大)</td>
<td></td>
<td></td>
<td>随机梯度下降</td>
<td></td>
<td></td>
<td>2</td>
</tr>
<tr>
<td>logistics分类</td>
<td>对一侧全0，另一侧全1的训练数据集建立分类器</td>
<td>计算对应最优参数的logistics function</td>
<td>梯度上升</td>
<td>概率期望最大</td>
<td>极大似然</td>
<td>3</td>
</tr>
<tr>
<td>softmax回归(logistics 可以看做k&#x3D;2时的特例)</td>
<td>分为k类</td>
<td>找到对应的拟合函数 并且拟合出参数</td>
<td>找拟合函数带入GLM 拟合参数老方法了</td>
<td>满足GLM的假设所以可以带入GLM</td>
<td>GLM 和 极大似然</td>
<td>4</td>
</tr>
<tr>
<td>高斯判别分析GDA</td>
<td>在n维多项高斯分布中找<code>一条线</code>分割训练集合</td>
<td>计算假设分布中对应参数</td>
<td>假设伯努利以及高斯分布运用极大似然算参数值</td>
<td>根据测试集带入模型得出的可能性的值来判断所属于的分类</td>
<td>n维高斯的分布矩阵形式的协方差 极大似然 贝叶斯 生成学习方法</td>
<td>5</td>
</tr>
<tr>
<td>朴素贝叶斯</td>
<td>直接概率公式计算可能性，如垃圾邮件根据词的出现进行分类</td>
<td>能够对含有大量特征与非特征的整体进行分类</td>
<td>直接算概率</td>
<td>通过可能性来判断是否是</td>
<td>贝叶斯 极大似然 生成学习方法</td>
<td>5</td>
</tr>
<tr>
<td>神经网络(只是提到没有深入讲)</td>
<td>非线性分类器</td>
<td>对非线性进行分类</td>
<td>极大似然，反向传播，梯度下降</td>
<td></td>
<td></td>
<td>6</td>
</tr>
<tr>
<td>最优边界分类器</td>
<td>也就是要找到最大几何间隔的分类器</td>
<td>期望在满足约束的情况下，表达式最大</td>
<td>在限定条件下的线性规划用对偶的方式求极值</td>
<td>期望在满足约束的情况下，使所有点到超平面距离的最小值最大</td>
<td>拉格朗日乘子法、KKT条件、拉格朗日对偶性</td>
<td>7</td>
</tr>
<tr>
<td>支持向量机SVM</td>
<td>对非线性可分割的分布进行分割</td>
<td>非线性分类器</td>
<td>说实话SVM以及SVM所依赖的知识的细节理解得还不够清晰 已经放入下面的TODO</td>
<td>把训练集转换到高维去，在高纬度中进行线性分割</td>
<td>核函数+最优边界分类器+对偶问题</td>
<td>6 7 8</td>
</tr>
<tr>
<td>L1 norm soft margin SVM</td>
<td>对于有错误分类</td>
<td>让带有惩罚项的表达式期望最小</td>
<td>数学推导</td>
<td>个别的错误项可以破坏支撑点 但仅仅算做惩罚</td>
<td>svm 极大似然</td>
<td>8</td>
</tr>
<tr>
<td>特征选择</td>
<td>例如文本分类</td>
<td>选取真正对文本类别有影响的特征</td>
<td>通过交叉验证 逐个插入检测对预测值的影响</td>
<td>运用实验获得模糊的相关性</td>
<td>贝叶斯</td>
<td>10</td>
</tr>
</tbody></table>
<h3 id="辅助方法-x2F-定义"><a href="#辅助方法-x2F-定义" class="headerlink" title="辅助方法&#x2F;定义"></a>辅助方法&#x2F;定义</h3><table>
<thead>
<tr>
<th>方法</th>
<th>功能</th>
<th>章节</th>
</tr>
</thead>
<tbody><tr>
<td>牛顿切线法</td>
<td>加快求极值点的收敛速度、二次收敛</td>
<td>4</td>
</tr>
<tr>
<td>GLM广义线性模型</td>
<td>对满足广义线性模型下的回归问题进行分析 直接得到所需要的拟合模型</td>
<td>4</td>
</tr>
<tr>
<td>拉普拉斯平滑</td>
<td>对于 处理例如朴素贝叶斯中可能出现的0&#x2F;0的概率 分子+1 分母+可分的类别数k</td>
<td>5</td>
</tr>
<tr>
<td>函数间隔</td>
<td>定义，当超平面的参数等比例缩放时超平面不会变但函数间隔会变化</td>
<td>6 7</td>
</tr>
<tr>
<td>几何间隔</td>
<td>同上，区别是 几何间隔&#x3D;函数间隔&#x2F;超平面法向量w的模,也就是当(w,b)等比例变化时，几何间隔不变 表示到超平面的距离</td>
<td>6 7</td>
</tr>
<tr>
<td>核函数</td>
<td>在最右边界分类器中出现了<code>&lt;X,X&gt;</code> 核函数能够降低计算代价,转换特征，同时选取高纬映射的核函数就够转化为SVM问题</td>
<td>7 8</td>
</tr>
<tr>
<td>SMO</td>
<td>每次修正一个参数逐步逼近，如果有等式约束每次修正两个</td>
<td>8</td>
</tr>
<tr>
<td>VC维</td>
<td>配合训练集 概率 错误率建立 误差上下界关系</td>
<td>10</td>
</tr>
<tr>
<td>交叉验证等多种验证</td>
<td>整体思想是把训练集的部分数据不用于训练而用于检验 进行模型筛选</td>
<td>10</td>
</tr>
<tr>
<td>规范化 正则化</td>
<td>防止过拟合</td>
<td>11</td>
</tr>
<tr>
<td>在线学习</td>
<td>边学习边预测 能收敛到分界线</td>
<td>11</td>
</tr>
<tr>
<td>检测机器学习算法的问题</td>
<td>通过 误差 方差 偏差 收敛性 值函数在更优秀的数据下的表现 综合判断问题所在</td>
<td>11</td>
</tr>
</tbody></table>
<h3 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h3><table>
<thead>
<tr>
<th>证明</th>
<th>方法</th>
<th>课程集数</th>
</tr>
</thead>
<tbody><tr>
<td>线性回归中用最小二乘法最好</td>
<td>概率分布假设+极大似然</td>
<td>3</td>
</tr>
<tr>
<td>线性回归 和 logistics分类对应的 拟合函数</td>
<td>按照GLM的方式对应带入</td>
<td>4</td>
</tr>
<tr>
<td>过拟合 欠拟合 经验风险的上下界</td>
<td>hoeffding不等式 同时能够提供定量分析误差</td>
<td>9 10</td>
</tr>
</tbody></table>
<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><ul>
<li>无样例(输入，输出)样本进行学习，直接根据未分类数据的分布特征，对数据进行分类&#x2F;建立带有功能的程序。</li>
</ul>
<h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><table>
<thead>
<tr>
<th>名称</th>
<th>功能</th>
<th>对应的期望</th>
<th>实现</th>
<th>理解</th>
<th>知识依赖</th>
<th>课程集数</th>
</tr>
</thead>
<tbody><tr>
<td>k-means</td>
<td>对无标记的点进行分类</td>
<td>找到分类的中心，使(按照每个分类的中心所得到的分类)的中心都是分类的中心</td>
<td>平面随机选中心，以这些点进行分类，对每个分好的类进行重新计算中心，重复直到收敛</td>
<td>分类的中心&#x3D;分类的中心 在概率上可能最大</td>
<td>不等式递推</td>
<td>12</td>
</tr>
<tr>
<td>最大期望算法EM</td>
<td>对无标记训练数据根据所假设的模型进行分类</td>
<td>在所对应假设的模型下找到最好的参数</td>
<td>通过假设隐藏已知中间变量计算中间变量的</td>
<td>E假设 概率可以看做优化Q，M步在这种情况下的分布带回去看作优化参数，再E再M直到收敛，可以说k-means也有点思路类似，也可以通过图形理解 坐标上升</td>
<td>贝叶斯 极大似然</td>
<td>12 13</td>
</tr>
<tr>
<td>因子分析模型</td>
<td>因子多 分类少，直接对角矩阵会丢失其它维度，用来进行分类</td>
<td>对无标示样本分类</td>
<td>加入低维隐含变量Z 猜测分布 进行升高维度加上高斯噪声再用EM</td>
<td>高维数据被分到低纬度的类中 可以反过来进行 映射+噪声的假设</td>
<td>EM 高斯 矩阵乘法</td>
<td>13 14</td>
</tr>
<tr>
<td>PCA主成分分析</td>
<td>降维投影提取真正关键的维度信息 例如LSI潜在语义索引</td>
<td>找多组让数据尽量分散的正交投影法向量</td>
<td>线性代数 matlab的SVD进行奇异值分解</td>
<td>找低前k个最大的向量</td>
<td>SVD 线性代数</td>
<td>14 15</td>
</tr>
<tr>
<td>ICA独立成分分析</td>
<td>提取分离独立成分 如音频分离</td>
<td>需要分布本身独立 且非高斯</td>
<td>数学推导</td>
<td>高位的平行四边形 找到轴 并把轴转换到正交轴</td>
<td>独立概率+sigmoid+极大似然</td>
<td>15</td>
</tr>
</tbody></table>
<h3 id="辅助方法-x2F-定义-1"><a href="#辅助方法-x2F-定义-1" class="headerlink" title="辅助方法&#x2F;定义"></a>辅助方法&#x2F;定义</h3><table>
<thead>
<tr>
<th>方法</th>
<th>功能</th>
<th>课程集数</th>
</tr>
</thead>
<tbody><tr>
<td>混合高斯分布GMM</td>
<td>无标记的空间上有多组服从独立的高斯分布的数据，用于作为EM算法的试例</td>
<td>12</td>
</tr>
<tr>
<td>Jensen不等式</td>
<td>如果f是凸函数 E[f(x)]&gt;&#x3D;f(EX)</td>
<td>12</td>
</tr>
</tbody></table>
<h2 id="强化学习RL-x2F-马尔科夫模型MDP"><a href="#强化学习RL-x2F-马尔科夫模型MDP" class="headerlink" title="强化学习RL&#x2F;马尔科夫模型MDP"></a>强化学习RL&#x2F;马尔科夫模型MDP</h2><p>上面的都是分类模型，强化学习要强行分类也可以说是无监督分类，或者半监督分类。</p>
<h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><table>
<thead>
<tr>
<th>名称</th>
<th>功能</th>
<th>对应的期望</th>
<th>实现</th>
<th>理解</th>
<th>知识依赖</th>
<th>课程集数</th>
</tr>
</thead>
<tbody><tr>
<td>马尔科夫决策过程<code>MDP(状态S，动作A，&#123;概率P(S,A)&#125;,折扣因子r,&#123;奖励函数R(S)&#125;)</code></td>
<td>对于给定的模型 能够根据当前状态做出模型下最优决策 如讲师所做的自动驾驶倒飞直升机XD</td>
<td><code>E(R(S0)+rR(S1)+r^2 *R(S2)+...)</code></td>
<td>值迭代&#x2F;策略迭代</td>
<td>值迭代是计算每个S下的期望最大值，再根据得到的期望得到决策；决策迭代是在过程中 决策和值共同更新，计算代价更大 小数据相对快</td>
<td>动态规划 期望</td>
<td>16</td>
</tr>
</tbody></table>
<h3 id="马尔科夫决策过程-变形-x2F-问题"><a href="#马尔科夫决策过程-变形-x2F-问题" class="headerlink" title="马尔科夫决策过程 变形&#x2F;问题"></a>马尔科夫决策过程 变形&#x2F;问题</h3><table>
<thead>
<tr>
<th>?</th>
<th>!</th>
<th>课程集数</th>
</tr>
</thead>
<tbody><tr>
<td>未知概率函数P</td>
<td>用实验所得尽心均值估计</td>
<td>16</td>
</tr>
<tr>
<td>对于维度高数量级大的 离散化难解决(数量级大 需要非均匀离散) 状态&gt;&#x3D;动作</td>
<td>通过建造模拟器<code>S(t+1)=S(t)+S&#39;(t)*dt</code>和实验数据进行线性拟合 从而取代P的作用，同时 需要多次多步骤实验</td>
<td>17</td>
</tr>
<tr>
<td>R(S)变为R(S,A)</td>
<td>依然用期望就好</td>
<td>18</td>
</tr>
<tr>
<td>从无限边界变为有限边界T，去掉折扣因子r，R和决策都还需要依赖时间</td>
<td>线性二次调节控制LQR 通过强假设 结束的S(T) A(T),进行反向递推(动规)，根据矩阵运算可以省去 噪音项</td>
<td>18 19</td>
</tr>
<tr>
<td>非线性函数</td>
<td>采用局部的 值点</td>
<td>19</td>
</tr>
<tr>
<td>模拟器不够好+非线性函数</td>
<td>局部切线值的点+LRQ -&gt;变为 微分动态规划DDP</td>
<td>19</td>
</tr>
<tr>
<td>无法获得真实值，只能获得观测值</td>
<td>Kalman滤波，非指数级别增长 通过概率估计推得可能的真实值&#x2F;极大似然</td>
<td>19</td>
</tr>
<tr>
<td>无法真实值的线性二次调节控制</td>
<td>LQG&#x3D;LQR+kalman滤波</td>
<td>19</td>
</tr>
<tr>
<td>LQG虽然能用但效果不是最佳，目标策略非线性策略</td>
<td>策略搜索:随机序列+带参数策略如logistics函数+梯度上升，找所假设的策略函数的最优参数</td>
<td>20</td>
</tr>
<tr>
<td>随机的序列 同样输入可能不同的值 拟合较难</td>
<td>Pegasus 序列依然随机生成，但生成后固定反复使用于训练</td>
<td>20</td>
</tr>
</tbody></table>
<h3 id="Debug-19"><a href="#Debug-19" class="headerlink" title="Debug 19"></a>Debug 19</h3><table>
<thead>
<tr>
<th>症状</th>
<th>方案</th>
</tr>
</thead>
<tbody><tr>
<td>模拟器可以 真实不行</td>
<td>改模拟器</td>
</tr>
<tr>
<td>人比RL好 但值函数人的低</td>
<td>改值函数</td>
</tr>
<tr>
<td>没有上述问题</td>
<td>改奖励函数</td>
</tr>
</tbody></table>
<h1 id="一句话能回答的知识点-TODO"><a href="#一句话能回答的知识点-TODO" class="headerlink" title="一句话能回答的知识点 TODO"></a>一句话能回答的知识点 TODO</h1><blockquote>
<p>梯度下降和梯度上升有什么区别？3</p>
</blockquote>
<p>画三维图形，求它的梯度，从图像上看，梯度是指向上方的。所以梯度下降用减法，实际是逼近极小值，而梯度上升用加法，逼近极大值。</p>
<blockquote>
<p>欠拟合与过拟合分别是什么？4</p>
</blockquote>
<p>欠拟合：模型复杂度不够 训练数据少，未能真正获取主要内在关系，训练数据和测试数据得分都低。过拟合，模型过于复杂，训练数据方差小得分高，但是测试数据偏差大 方差大</p>
<blockquote>
<p>判别学习法 和 生成学习方法 的区别？5</p>
</blockquote>
<p>判别学习法直接对P(y|x)进行建模；生成学习方法对P(x|y) 和 p(y)进行建模 然后，y &#x3D; 贝叶斯公式转换后最大的y 例如 隐马尔可夫模型HMM、朴素贝叶斯模型、高斯混合模型GMM、LDA。</p>
<blockquote>
<p>GDA与Logistics模型比较？5</p>
</blockquote>
<p>GDA按照概率转化的曲线和sigmoid,很相似。GDA更强的假设，对于正确的训练集，GDA效率更高 更好，但对于不正确的模型，logistic的健壮性robust更好</p>
<h1 id="其它知识点-细节-TODO"><a href="#其它知识点-细节-TODO" class="headerlink" title="其它知识点 细节 TODO"></a>其它知识点 细节 TODO</h1><p>LGM</p>
<p>对偶问题</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/johnnyconstantine/article/details/46335763">KKT条件</a></p>
<p>核函数定义 证明 应用 具体核(高斯核)</p>
<p>SVM</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zouxy09/article/details/8537620">EM</a></p>
<p>EM:<code>Do, C. B., &amp; Batzoglou, S. (2008). What is the expectation maximization algorithm?. Nature biotechnology, 26(8), 897.</code></p>
<h1 id="其它TODO"><a href="#其它TODO" class="headerlink" title="其它TODO"></a>其它TODO</h1><p>添加配图</p>
<p>李航的《统计学习方法》刚翻了个开头，这本书先讲的泛的再具体的顺序不同，不过瞄了目录，似乎有新内容还是换了个名字？不懂2333，目前计划是先不看它，去看CSP，之后再看<code>_(:з」∠)_</code>。</p>
<blockquote>
<p>老师建议把 证明过程盖住 自己再证明</p>
</blockquote>
<p>2讲矩阵梯度公式</p>

    </div>

    
    
    
      


    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>作者： </strong>Xiao Ye
  </li>
  <li class="post-copyright-link">
      <strong>文章連結：</strong>
      <a href="https://yexiaorain.github.io/Blog/2018-04-17-Stanford_Machine_Learning/" title="Stanford Machine Learning 学习笔记、个人整理">https://yexiaorain.github.io/Blog/2018-04-17-Stanford_Machine_Learning/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版權聲明： </strong>本網誌所有文章除特別聲明外，均採用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 許可協議。轉載請註明出處！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/Blog/tags/Machine-learning/" rel="tag"><i class="fa fa-tag"></i> Machine learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/Blog/cf/908D/" rel="prev" title="CF Goodbye2017 D(math:series + extended Euclidean + dp)">
                  <i class="fa fa-chevron-left"></i> CF Goodbye2017 D(math:series + extended Euclidean + dp)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/Blog/2018-04-18-Stanford_Machine_Learning_with_graph/" rel="next" title="Stanford Machine Learning 科普">
                  Stanford Machine Learning 科普 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiao Ye</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="總字數">424k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="所需總閱讀時間">23:34</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/Blog/js/comments.js"></script><script src="/Blog/js/utils.js"></script><script src="/Blog/js/schemes/muse.js"></script><script src="/Blog/js/next-boot.js"></script><script src="/Blog/js/bookmark.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/Blog/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/Blog/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.2.0/quicklink.umd.js" integrity="sha256-4kQf9z5ntdQrzsBC3YSHnEz02Z9C1UeW/E9OgnvlzSY=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://yexiaorain.github.io/Blog/2018-04-17-Stanford_Machine_Learning/"}</script>
  <script src="/Blog/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"yexiaorain","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/Blog/js/third-party/comments/disqus.js"></script>

</body>
</html>
